# Summary

* With _Monte Carlo_, we update the value function from a complete episode, and so we **use the actual accurate discounted return of this episode.**
* With _TD Learning_, we update the value function from a step, and we replace ğºğ‘¡, which we donâ€™t know, with **an estimated return called the TD target.**

<figure><img src="../../.gitbook/assets/Summary.png" alt=""><figcaption></figcaption></figure>
